{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200f271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "langchain_project = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "endpoint = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "tracing = os.getenv(\"LANGSMITH_TRACING\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905de5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='models/gemini-2.0-flash' google_api_key=SecretStr('**********') client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000025171E2EFF0> default_metadata=()\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Agentic AI refers to a type of artificial intelligence capable of independent action and decision-making to achieve specific goals. Unlike traditional AI systems that primarily react to inputs and follow pre-programmed instructions, agentic AI can:\\n\\n*   **Perceive its environment:** Gather information from its surroundings through sensors, APIs, or other data sources.\\n*   **Reason and plan:** Analyze the information, set goals, and develop strategies to achieve them.\\n*   **Act autonomously:** Execute plans and take actions in the real world or digital environments without constant human intervention.\\n*   **Learn and adapt:** Evaluate the outcomes of its actions and adjust its strategies to improve performance over time.\\n\\nHere's a breakdown of key aspects:\\n\\n*   **Autonomy:** A core characteristic. Agentic AI systems operate with a degree of independence, making choices on their own.\\n*   **Goal-oriented:** They are designed to achieve specific objectives, whether it's solving a problem, completing a task, or optimizing a process.\\n*   **Proactive:** They don't just wait for instructions; they actively seek out information and opportunities to advance their goals.\\n*   **Adaptive:** They can learn from experience and adjust their behavior based on feedback and changing circumstances.\\n*   **Complex Reasoning:** They often incorporate advanced AI techniques like natural language processing, machine learning, and knowledge representation to reason about the world and make informed decisions.\\n\\nExamples of Agentic AI:\\n\\n*   **Autonomous Vehicles:** Cars that can navigate roads, avoid obstacles, and reach destinations without human control.\\n*   **AI-powered Chatbots:** Chatbots that can understand user needs, provide personalized recommendations, and resolve issues independently.\\n*   **Robotic Process Automation (RPA) with AI:** Systems that can automate complex business processes, such as invoice processing or customer onboarding, by making decisions and adapting to changing conditions.\\n*   **Personal Assistants:** Digital assistants that can manage schedules, make reservations, and provide information based on user preferences and context.\\n*   **Drug Discovery:** AI systems that can analyze vast datasets of chemical compounds, design experiments, and identify potential drug candidates.\\n\\nBenefits of Agentic AI:\\n\\n*   **Increased Efficiency:** Automating tasks and processes can free up human workers to focus on more creative and strategic activities.\\n*   **Improved Decision-Making:** AI can analyze data and identify patterns that humans might miss, leading to better decisions.\\n*   **Enhanced Productivity:** By working autonomously, AI agents can operate continuously and handle large volumes of work.\\n*   **New Possibilities:** Agentic AI can unlock new possibilities in various fields, such as healthcare, finance, and transportation.\\n\\nChallenges of Agentic AI:\\n\\n*   **Ethical Concerns:** Ensuring that AI agents act ethically and align with human values is crucial.\\n*   **Safety Risks:** Autonomous systems can pose safety risks if they malfunction or make incorrect decisions.\\n*   **Job Displacement:** The automation of tasks by AI agents could lead to job displacement in some industries.\\n*   **Complexity:** Developing and deploying agentic AI systems can be complex and require specialized expertise.\\n*   **Explainability:** Understanding how AI agents make decisions can be challenging, making it difficult to trust and control them.\\n\\nIn summary, agentic AI represents a significant step forward in AI development, enabling machines to act more independently and intelligently. As the technology continues to evolve, it has the potential to transform many aspects of our lives, but it also raises important ethical and societal considerations that need to be addressed.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--698ec3dd-33dc-4e5a-83e7-33e4ad4d07f5-0' usage_metadata={'input_tokens': 6, 'output_tokens': 734, 'total_tokens': 740, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is agentic AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to a type of artificial intelligence capable of independent action and decision-making to achieve specific goals. Unlike traditional AI systems that primarily react to inputs and follow pre-programmed instructions, agentic AI can:\n",
      "\n",
      "*   **Perceive its environment:** Gather information from its surroundings through sensors, APIs, or other data sources.\n",
      "*   **Reason and plan:** Analyze the information, set goals, and develop strategies to achieve them.\n",
      "*   **Act autonomously:** Execute plans and take actions in the real world or digital environments without constant human intervention.\n",
      "*   **Learn and adapt:** Evaluate the outcomes of its actions and adjust its strategies to improve performance over time.\n",
      "\n",
      "Here's a breakdown of key aspects:\n",
      "\n",
      "*   **Autonomy:** A core characteristic. Agentic AI systems operate with a degree of independence, making choices on their own.\n",
      "*   **Goal-oriented:** They are designed to achieve specific objectives, whether it's solving a problem, completing a task, or optimizing a process.\n",
      "*   **Proactive:** They don't just wait for instructions; they actively seek out information and opportunities to advance their goals.\n",
      "*   **Adaptive:** They can learn from experience and adjust their behavior based on feedback and changing circumstances.\n",
      "*   **Complex Reasoning:** They often incorporate advanced AI techniques like natural language processing, machine learning, and knowledge representation to reason about the world and make informed decisions.\n",
      "\n",
      "Examples of Agentic AI:\n",
      "\n",
      "*   **Autonomous Vehicles:** Cars that can navigate roads, avoid obstacles, and reach destinations without human control.\n",
      "*   **AI-powered Chatbots:** Chatbots that can understand user needs, provide personalized recommendations, and resolve issues independently.\n",
      "*   **Robotic Process Automation (RPA) with AI:** Systems that can automate complex business processes, such as invoice processing or customer onboarding, by making decisions and adapting to changing conditions.\n",
      "*   **Personal Assistants:** Digital assistants that can manage schedules, make reservations, and provide information based on user preferences and context.\n",
      "*   **Drug Discovery:** AI systems that can analyze vast datasets of chemical compounds, design experiments, and identify potential drug candidates.\n",
      "\n",
      "Benefits of Agentic AI:\n",
      "\n",
      "*   **Increased Efficiency:** Automating tasks and processes can free up human workers to focus on more creative and strategic activities.\n",
      "*   **Improved Decision-Making:** AI can analyze data and identify patterns that humans might miss, leading to better decisions.\n",
      "*   **Enhanced Productivity:** By working autonomously, AI agents can operate continuously and handle large volumes of work.\n",
      "*   **New Possibilities:** Agentic AI can unlock new possibilities in various fields, such as healthcare, finance, and transportation.\n",
      "\n",
      "Challenges of Agentic AI:\n",
      "\n",
      "*   **Ethical Concerns:** Ensuring that AI agents act ethically and align with human values is crucial.\n",
      "*   **Safety Risks:** Autonomous systems can pose safety risks if they malfunction or make incorrect decisions.\n",
      "*   **Job Displacement:** The automation of tasks by AI agents could lead to job displacement in some industries.\n",
      "*   **Complexity:** Developing and deploying agentic AI systems can be complex and require specialized expertise.\n",
      "*   **Explainability:** Understanding how AI agents make decisions can be challenging, making it difficult to trust and control them.\n",
      "\n",
      "In summary, agentic AI represents a significant step forward in AI development, enabling machines to act more independently and intelligently. As the technology continues to evolve, it has the potential to transform many aspects of our lives, but it also raises important ethical and societal considerations that need to be addressed.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bac3b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x0000025172F58350> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000251794572C0> model_name='qwen-qwq-32b' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_llm = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "\n",
    "print(groq_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba43c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user said \"My name is Gaurav.\" I need to respond appropriately. Let me start by acknowledging their name. Maybe say something friendly like \"Hello Gaurav!\" Then I should offer assistance. I should ask how I can help them today. Keep it simple and open-ended so they feel comfortable to ask anything. Let me check if there\\'s anything else I should consider. No, that\\'s probably enough. Make sure the tone is welcoming and helpful. Alright, that should work.\\n</think>\\n\\nHello Gaurav! Nice to meet you. How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything specific! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 16, 'total_tokens': 159, 'completion_time': 0.324591781, 'prompt_time': 0.002902855, 'queue_time': 0.266472066, 'total_time': 0.327494636}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_28178d7ff6', 'finish_reason': 'stop', 'logprobs': None}, id='run--19a4b24c-0a41-412d-a41e-2951e7cb9cfe-0', usage_metadata={'input_tokens': 16, 'output_tokens': 143, 'total_tokens': 159})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm.invoke(\"My name is Gaurav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca044ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user asked, \"What is my name?\" Let me figure out how to respond.\\n\\nFirst, I need to recall that I can\\'t access any personal information about the user. My programming restricts me from knowing or storing personal data. So, I can\\'t tell them their name directly. \\n\\nBut maybe they want to know how to find out their name themselves. I should consider different scenarios. If they\\'re logged into an account, like on a website or app, their name might be in their profile. Or maybe they\\'re using a device where they\\'ve set up their name in the system settings. \\n\\nAlternatively, if they\\'re asking in a conversation where others know them, they could ask someone else. I should present these options without assuming their specific situation. \\n\\nI should also make sure to explain that I can\\'t provide their name because of privacy reasons. It\\'s important to be helpful but respectful of their privacy. \\n\\nLet me structure the response: start by stating I can\\'t know their name, then offer possible ways they can find it themselves, and maybe suggest they check their account settings or device preferences. Keep it friendly and clear.\\n</think>\\n\\nI don\\'t have access to personal information or the ability to know your name. However, if you\\'re asking how to find out your own name, here are some common ways to do so:\\n\\n- **Check your account profile:** If you\\'re logged into an online service or app (like email, social media, or a banking site), your name might be listed under your account settings.  \\n- **Look at official documents:** Your name is usually listed on identification documents (e.g., driver\\'s license, passport, or government-issued IDs).  \\n- **Ask someone close to you:** A family member, friend, or colleague might know your name if you\\'re unsure.  \\n\\nLet me know if you\\'d like help with anything else! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 387, 'prompt_tokens': 15, 'total_tokens': 402, 'completion_time': 0.881192884, 'prompt_time': 0.002745033, 'queue_time': 0.405763917, 'total_time': 0.883937917}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc228d51-fc6b-4c97-8251-1c1d0dbfe831-0', usage_metadata={'input_tokens': 15, 'output_tokens': 387, 'total_tokens': 402})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm.invoke(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e202907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user is asking about Agentic AI. Let me start by recalling what I know about this term. From what I remember, Agentic AI refers to a concept where AI systems are designed to operate autonomously, making decisions and taking actions in the real world without constant human intervention. But I need to make sure I\\'m accurate here.\\n\\nFirst, I should break down the term. \"Agentic\" relates to agency, meaning the capacity to act independently to achieve a goal. So Agentic AI would be systems with a high degree of autonomy. Now, how does this differ from other AI concepts like autonomous systems or general AI? Maybe Agentic AI emphasizes the decision-making process and the ability to act in complex environments. \\n\\nI should check if there\\'s a specific framework or model associated with Agentic AI. I recall that some researchers, like Ben Goertzel, have discussed agentic AI in the context of creating systems that can self-direct their learning and goals. Also, I think it\\'s related to the idea of agents in AI, like software agents, but taken further in terms of autonomy and adaptability.\\n\\nApplications might include things like self-driving cars, but perhaps more advanced where the AI can not only drive but also make decisions about maintenance, route changes, etc., without needing a programmer\\'s input each time. Another example could be in robotic process automation, where AI handles various business processes autonomously.\\n\\nI need to mention key features. Autonomy is central. Then there\\'s adaptability, the ability to adjust to new situations. Goal orientation, meaning the AI has its own objectives. Learning and evolution over time, maybe through reinforcement learning or other methods. Collaboration with other systems and humans, which might involve coordination protocols. Ethical considerations are important too, like ensuring the AI\\'s actions align with ethical standards and prevent unintended consequences.\\n\\nPotential challenges: Safety is a big one. How do you ensure an autonomous AI doesn\\'t cause harm? Then there\\'s the issue of accountabilityâ€”if an AI makes a mistake, who is responsible? Technical challenges include creating systems that can handle the vast array of real-world scenarios. Ethical alignment is another challenge to ensure AI goals don\\'t conflict with human values.\\n\\nApplications beyond the examples I thought of could include healthcare (like AI managing patient data and treatment plans adaptively), finance (automated trading with adaptive strategies), or even space exploration where robots manage missions without real-time human control.\\n\\nWait, but is Agentic AI a well-established term or more of a conceptual idea? I should clarify that it\\'s an emerging concept, still under development. It\\'s part of the broader field of artificial general intelligence (AGI), aiming for systems with human-like autonomy.\\n\\nAlso, might want to touch on related fields like reinforcement learning, multi-agent systems, and maybe even ethics in AI. It\\'s important to distinguish Agentic AI from narrow AI, which is task-specific and not autonomous in the same way.\\n\\nI should also mention examples of current research or projects that are moving towards Agentic AI. For instance, some companies are developing self-learning systems, or AI that can set its own subgoals. Projects like OpenAI\\'s work on autonomous agents or DeepMind\\'s efforts in decision-making models could be relevant.\\n\\nWait, but I need to be careful not to conflate Agentic AI with existing concepts. Maybe some sources use \"agentic\" to describe systems that act as agents, but the term might have specific nuances in academic literature. I should check if there\\'s a standard definition. Hmm, perhaps looking into papers or articles where the term is used. Since I can\\'t browse the web, I\\'ll rely on my existing knowledge.\\n\\nIn summary, Agentic AI is about AI with significant autonomy, decision-making, adaptability, and agency. It\\'s still in research phases and has challenges related to safety and ethics. Applications are in areas requiring autonomous decision-making. I should present this in a structured way, defining it, key features, applications, challenges, and future outlook.\\n</think>\\n\\nAgentic AI refers to a concept in artificial intelligence (AI) where systems are designed to operate autonomously, with the capacity for decision-making, goal-directed behavior, and adaptability to achieve objectives in dynamic environments. Here\\'s a structured overview:\\n\\n### **Core Definition**:\\n- **Agency**: Agentic AI embodies the principle of **agency**, meaning the system can act independently, set its own sub-goals, and make decisions without continuous human intervention.\\n- **Autonomy**: It operates with a high degree of independence in planning, executing tasks, and learning from experiences.\\n\\n### **Key Features**:\\n1. **Autonomy**: \\n   - Operates without constant human oversight, especially in unstructured or unpredictable environments.\\n   - Examples include self-driving cars adjusting to real-time traffic or robots managing space missions autonomously.\\n\\n2. **Adaptability**:\\n   - Adapts to new situations through learning (e.g., reinforcement learning), evolving strategies to achieve goals over time.\\n   - For instance, an AI system adjusting trading strategies in real-time financial markets.\\n\\n3. **Goal-Orientation**:\\n   - Pursues predefined or self-defined objectives, prioritizing actions to optimize outcomes (e.g., an AI optimizing energy usage in a smart grid).\\n\\n4. **Learning & Evolution**:\\n   - Continuously improves through experience, possibly redefining its own goals or constraints (e.g., a medical AI refining diagnostic protocols based on patient outcomes).\\n\\n5. **Collaboration**:\\n   - Works with humans, other AI agents, or systems, requiring coordination and communication (e.g., in multi-agent robotics or collaborative healthcare systems).\\n\\n6. **Ethical & Societal Alignment**:\\n   - Designed to align with ethical principles and human values, ensuring beneficial outcomes (e.g., avoiding biases in decision-making).\\n\\n### **Applications**:\\n- **Autonomous Systems**: Self-driving vehicles, drones, or robots in manufacturing or disaster response.\\n- **Healthcare**: AI managing patient care, from diagnostics to treatment adjustments.\\n- **Finance**: Adaptive trading algorithms or fraud detection systems.\\n- **Space Exploration**: Probes or rovers exploring remote environments without real-time human control.\\n- **Climate Modeling**: Systems autonomously analyzing data and suggesting environmental interventions.\\n\\n### **Challenges**:\\n1. **Safety & Reliability**:\\n   - Ensuring the system behaves predictably in complex, unforeseen scenarios (e.g., avoiding catastrophic errors in critical infrastructure).\\n\\n2. **Accountability**:\\n   - Determining responsibility when an AI makes a harmful decision (e.g., in healthcare or criminal justice).\\n\\n3. **Ethical Alignment**:\\n   - Programming ethical principles into AI to prevent misalignment with human values (e.g., avoiding biased outcomes).\\n\\n4. **Technical Complexity**:\\n   - Developing robust systems capable of long-term autonomy in unstructured environments.\\n   - Balancing efficiency with transparency (the \"black box\" problem).\\n\\n5. **Interoperability**:\\n   - Ensuring agentic systems can work seamlessly with humans and other AI agents without conflicts or errors.\\n\\n### **Related Concepts**:\\n- **Artificial General Intelligence (AGI)**: Agentic AI overlaps with AGI research, aiming for systems with human-like cognitive flexibility.\\n- **Autonomous Agents**: A broader field, but Agentic AI emphasizes advanced self-direction and ethical alignment.\\n- **Multi-Agent Systems**: Focuses on coordination among multiple agents, often in distributed environments.\\n\\n### **Research & Development**:\\n- **Ben Goertzel**: A proponent of agentic AI, emphasizing systems that can self-direct learning and goals (e.g., his work on OpenCog).\\n- **Reinforcement Learning (RL)**: Critical for enabling adaptive decision-making in autonomous systems.\\n- **Human-AI Collaboration**: Research into hybrid systems where humans and AI co-evolve goals (e.g., in workplace automation).\\n\\n### **Future Outlook**:\\n- **Potential Benefits**: Enhanced efficiency in complex tasks, reduced human workload in dangerous or repetitive jobs, and innovation in problem-solving.\\n- **Ethical Imperatives**: Requires robust frameworks for safety, explainability, and governance to prevent misuse or unintended consequences.\\n- **Regulation**: Likely to require international standards and ethical guidelines to ensure responsible deployment.\\n\\n### **Example Use Cases**:\\n- A logistics system autonomously rerouting delivery drones during a natural disaster while optimizing for safety and efficiency.\\n- A smart city grid managing energy distribution dynamically, adapting to weather, demand fluctuations, and emergencies.\\n\\n### **Key Distinctions**:\\n- **vs. Narrow AI**: Agentic AI is not task-specific but can generalize across contexts and redefine goals, unlike tools like Siri or chatbots.\\n- **vs. Autonomous Systems**: While autonomous systems (e.g., drones) operate without direct control, Agentic AI emphasizes *self-directed learning* and *ethical alignment*.\\n\\n### **Conclusion**:\\nAgentic AI represents an aspirational vision of AI systems that combine autonomy, adaptability, and ethical awareness. While still largely in research and early stages of application, it holds promise for transformative advancements but requires careful consideration of ethical, technical, and societal implications.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1849, 'prompt_tokens': 16, 'total_tokens': 1865, 'completion_time': 4.514642594, 'prompt_time': 0.003109124, 'queue_time': 0.25095204699999996, 'total_time': 4.5177517179999995}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'stop', 'logprobs': None}, id='run--946db2ea-1e0e-4e52-b3de-b4ad0cf2f7dd-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1849, 'total_tokens': 1865})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm.invoke(\"What is Agentic AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f44ae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0029225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6d450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000251730E1250>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000251730E2060>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chaining - combines prompt with llm\n",
    "\n",
    "chain = prompt|llm \n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db425e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI Engineer, I can definitely tell you about Langsmith!\n",
      "\n",
      "**Langsmith** is an open-source platform designed to simplify and accelerate the development of large language models (LLMs). It's built around the concept of making the process of fine-tuning and deploying LLMs more accessible to a wider audience, not just large research institutions.\n",
      "\n",
      "Here are some key features and benefits of Langsmith:\n",
      "\n",
      "* **User-friendly interface:** Langsmith provides a web-based interface that makes it easy to interact with LLMs, even for users without extensive coding experience.\n",
      "* **Streamlined fine-tuning process:** It offers tools and workflows to efficiently fine-tune existing LLMs on specific tasks or datasets.\n",
      "* **Community-driven development:** As an open-source project, Langsmith benefits from the contributions and feedback of a large community of developers and researchers.\n",
      "* **Support for various LLMs:**  Langsmith is designed to work with multiple LLM architectures, including those from popular frameworks like Hugging Face Transformers.\n",
      "* **Multi-modal capabilities:** While primarily focused on text, Langsmith is also exploring support for other modalities like images and audio.\n",
      "\n",
      "**Here's how Langsmith can be beneficial:**\n",
      "\n",
      "* **Faster prototyping:** Researchers and developers can quickly experiment with different LLM architectures and fine-tuning techniques.\n",
      "* **Reduced development costs:** By simplifying the process, Langsmith can help lower the barrier to entry for LLM development.\n",
      "* **Improved accessibility:**  Making LLMs more accessible to a wider range of users can lead to more innovative applications and solutions.\n",
      "\n",
      "**Overall, Langsmith is a promising platform that has the potential to democratize access to LLMs and accelerate their development and adoption.**\n",
      "\n",
      "If you're interested in learning more, I recommend checking out their official website and documentation: [https://www.langsmith.ai/](https://www.langsmith.ai/)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## invoke the chain\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me something about Langsmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d08c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is an open-source platform designed to simplify the process of developing and deploying large language models (LLMs). Think of it as a streamlined toolbox for anyone wanting to work with powerful AI like ChatGPT, but with more control and customization. \n",
      "\n",
      "Here's a breakdown of what makes Langsmith special:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Model Management:** Langsmith lets you easily manage different LLMs, switching between them effortlessly. You can even fine-tune existing models to suit your specific needs.\n",
      "* **Experiment Tracking:**  It keeps track of all your experiments, making it easier to compare results, understand what works, and iterate on your models.\n",
      "* **Prompt Engineering:** Langsmith offers tools to help you craft effective prompts for your LLMs, leading to more accurate and relevant responses.\n",
      "* **Data Handling:** It provides features for efficiently loading, preprocessing, and managing the data your models learn from.\n",
      "* **Deployment Flexibility:**  Once your model is trained, Langsmith helps you deploy it in various ways, including as a web application or API.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Accessibility:** Langsmith lowers the barrier to entry for LLM development, making it accessible to a wider range of users, not just AI experts.\n",
      "* **Efficiency:** Streamlined workflows and built-in tools save you time and effort compared to building everything from scratch.\n",
      "* **Customization:** You have fine-grained control over your models and deployments, allowing you to tailor them to your specific use cases.\n",
      "* **Collaboration:** Langsmith fosters collaboration by making it easier to share models, experiments, and findings with others.\n",
      "\n",
      "**Who is Langsmith for?**\n",
      "\n",
      "* **Researchers:** Explore new LLM architectures and techniques.\n",
      "* **Developers:** Build custom AI applications powered by LLMs.\n",
      "* **Educators:** Teach students about AI and LLM development in a hands-on way.\n",
      "* **Anyone interested in AI:** Experiment with cutting-edge technology and see what's possible.\n",
      "\n",
      "\n",
      "Langsmith is a powerful platform that's democratizing access to the world of LLMs. If you're looking to dive into the exciting realm of AI, Langsmith is definitely worth checking out!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## OutputParser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "new_chain = prompt|llm|output_parser\n",
    "response = new_chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be58f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "output_parser = JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ec8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "### JSONOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "701f800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522dca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for developing, deploying, and managing AI assistants.', 'features': ['Modular design allows for customization and extensibility.', 'Supports multiple language models, including open-source and proprietary ones.', 'Provides tools for fine-tuning and evaluating AI assistants.', 'Offers a user-friendly interface for interacting with AI assistants.', 'Facilitates collaboration and sharing of AI assistant models.'], 'benefits': ['Empowers developers to build custom AI assistants tailored to specific needs.', 'Reduces the barrier to entry for developing and deploying AI assistants.', 'Promotes transparency and accessibility in AI development.', 'Fosters a community of developers and researchers working on AI assistants.', 'Offers a cost-effective solution for building and maintaining AI assistants.'], 'website': 'https://github.com/facebookresearch/langs'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57b4d4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Langsmith is an open-source framework developed by AI21 Labs that simplifies the process of building and deploying AI-powered applications using large language models (LLMs). \\n\\n  **Key Features:**\\n\\n  * **Modular Design:** Langsmith allows developers to easily integrate different components, such as LLMs, prompt engineering tools, and evaluation metrics, into their applications.\\n  * **Prompt Engineering:** It provides a user-friendly interface and tools to help developers create effective prompts for LLMs, leading to better performance and more accurate results.\\n  * **Model Management:** Langsmith simplifies the process of managing and deploying different LLMs, including fine-tuning existing models for specific tasks.\\n  * **Pipeline Creation:** Developers can build complex AI pipelines by chaining together different components, enabling them to create sophisticated applications.\\n  * **Data Augmentation:** Langsmith offers tools for data augmentation, which can improve the performance of LLMs by expanding the training data.\\n\\n  **Benefits:**\\n\\n  * **Accessibility:** Langsmith makes LLMs more accessible to developers by providing a user-friendly framework and removing the need for extensive technical expertise.\\n  * **Efficiency:** The modular design and automation features of Langsmith streamline the development process, saving time and resources.\\n  * **Customization:** Developers can tailor Langsmith to their specific needs by integrating their own models, tools, and data.\\n  * **Collaboration:** The open-source nature of Langsmith allows for community contributions and collaboration, fostering innovation and improvement.\\n\\n  **Use Cases:**\\n\\n  Langsmith can be used for a wide range of applications, including:\\n\\n  * Chatbots and conversational AI\\n  * Text summarization and generation\\n  * Question answering and information retrieval\\n  * Code generation and debugging\\n  * Content creation and marketing\\n\\n  Langsmith is a powerful tool that empowers developers to leverage the capabilities of LLMs and build innovative AI-powered applications.'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab83b877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in XML markup format with <output>  tags.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in XML markup format with <output>  tags.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c9fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': '\\n\\nLangsmith is an open-source framework developed by the LangChain team that focuses on streamlining the development of applications powered by large language models (LLMs). \\n\\nHere are some key aspects of Langsmith:\\n\\n* **Simplifies LLM Integration:** Langsmith provides tools and abstractions to easily integrate LLMs into your applications, abstracting away the complexities of interacting with different LLM APIs and models.\\n\\n* **Modular Design:** It follows a modular architecture, allowing you to customize and extend its functionality by combining different components like chains, prompts, and agents.\\n\\n* **Chain Creation:** Langsmith excels in creating complex LLM-powered workflows called \"chains.\" Chains can involve multiple LLM calls, data retrieval, and other operations, enabling you to build sophisticated applications.\\n\\n* **Prompt Engineering:** It offers features to help with prompt engineering, a crucial aspect of working with LLMs. Langsmith provides tools for testing, refining, and managing prompts.\\n\\n* **Agent Capabilities:** Langsmith supports the development of \"agents,\" which are LLMs that can interact with the world through APIs and external tools. This allows for more autonomous and capable applications.\\n\\n* **Open-Source and Community-Driven:** Being open-source, Langsmith encourages collaboration and contributions from the community, fostering innovation and rapid development.\\n\\n**In essence, Langsmith aims to make it easier and more efficient for developers to build powerful and innovative applications leveraging the capabilities of LLMs.**\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3079f564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "# We will add these instructions to the prompt below\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df3e85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a shortened filmography for Tom Hanks, focusing on some of his most notable roles:\n",
      "\n",
      "* <movie>He Knows You're Alone</movie> (1980)\n",
      "* <movie>Splash</movie> (1984)\n",
      "* <movie>Big</movie> (1988)\n",
      "* <movie>Joe Versus the Volcano</movie> (1990)\n",
      "* <movie>A League of Their Own</movie> (1992)\n",
      "* <movie>Philadelphia</movie> (1993)\n",
      "* <movie>Forrest Gump</movie> (1994)\n",
      "* <movie>Apollo 13</movie> (1995)\n",
      "* <movie>Toy Story</movie> (1995) \n",
      "* <movie>Saving Private Ryan</movie> (1998)\n",
      "* <movie>Cast Away</movie> (2000)\n",
      "* <movie>The Da Vinci Code</movie> (2006)\n",
      "* <movie>Catch Me If You Can</movie> (2002)\n",
      "* <movie>Toy Story 3</movie> (2010)\n",
      "* <movie>Bridge of Spies</movie> (2015)\n",
      "* <movie>Sully</movie> (2016)\n",
      "* <movie>A Beautiful Day in the Neighborhood</movie> (2019)\n",
      "* <movie>Greyhound</movie> (2020)\n",
      "\n",
      "\n",
      "\n",
      "This is just a small selection of his work.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "125a09bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = XMLOutputParser()\n",
    "\n",
    "# We will add these instructions to the prompt below\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actor': [{'name': 'Tom Hanks'}, {'films': [{'film': [{'title': 'Saving Private Ryan'}, {'year': '1998'}]}, {'film': [{'title': 'Forrest Gump'}, {'year': '1994'}]}, {'film': [{'title': 'Apollo 13'}, {'year': '1995'}]}, {'film': [{'title': 'Toy Story'}, {'year': '1995'}]}, {'film': [{'title': 'Cast Away'}, {'year': '2000'}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"query\": actor_query})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58ecb5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\n[\\'movies\\', \\'actor\\', \\'film\\', \\'name\\', \\'genre\\']\\n```'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = XMLOutputParser(tags=[\"movies\", \"actor\", \"film\", \"name\", \"genre\"])\n",
    "\n",
    "# We will add these instructions to the prompt below\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0676d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movies': [{'actor': [{'name': 'Tom Hanks'}, {'film': [{'name': 'Forrest Gump'}, {'genre': 'Comedy, Drama, Romance'}]}, {'film': [{'name': 'Saving Private Ryan'}, {'genre': 'War, Drama'}]}, {'film': [{'name': 'Toy Story'}, {'genre': 'Animation, Adventure, Comedy'}]}, {'film': [{'name': 'Apollo 13'}, {'genre': 'Drama, History, Thriller'}]}, {'film': [{'name': 'Cast Away'}, {'genre': 'Adventure, Drama, Thriller'}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"query\": actor_query})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d589274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why don't scientists trust atoms? Because they make up everything!\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "508b7f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Smart Coffee Mug', 'price': 35}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Assignment \n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(description=\"question to set up a product\")\n",
    "    price: int = Field(description=\"price of a product in USD\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "prod_query = \"Tell me a dummy product name with price in USD\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Product)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": prod_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
